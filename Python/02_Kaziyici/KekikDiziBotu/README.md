# Python ile Dizi Botu Yapmak

ğŸ•Š Bu dÃ¶kÃ¼man **[@KekikAkademi](https://t.me/KekikAkademi)** iÃ§in oluÅŸturulmuÅŸtur. âœŒğŸ¼

![](https://teletype.in/files/f8/44/f844fcdd-a2eb-4c15-8e46-193ccd80c056.png)

Dostlar merabayÄ±n,  
Bu yazÄ±mÄ±zda `requests` ve `BeautifulSoup` modÃ¼llerini kullanarak **dizibox** sitesindeki bÃ¼tÃ¼n dizilerin bilgilerini Ã§ekmeyi Ã¶ÄŸreneceÄŸiz.

> **Burada Ã¶ÄŸrenecekleriniz ile** _istediÄŸiniz websitesinden istediÄŸiniz veriyi rahatlÄ±kla ayÄ±klayabileceksiniz.._

Hadi, hemen baÅŸlayalÄ±m;

## Senaryo
1.  Siteye **istek**(`request`) **yolla** _ve_ **sana yanÄ±t versin.** 
{`Response [200]`}
2.  Sitedeki **bÃ¼tÃ¼n** _dizi_ **linklerini belirle.**
(`Web Crawling`)
3.  **Belirlenen baÄŸlantÄ±larÄ±**(_linkleri_) **gez.**
4.  **GezdiÄŸin linklerden** _dizinin_: _Ad, AÃ§Ä±klama, Ãœlke ve TÃ¼r_ **bilgilerini toparla.**  
    (`Web Scraping`)

### Web Crawling
[Neydi bu olay](https://kekikakademi.site/Python-ile-Veri-Kazima?cda=); _herhangi bir site Ã¼zerinde gezinmek ve hedef site Ã¼zerinde yer alan linkleri toplamak_ demekti.  
_Web Crawler_â€™Ä±n temelde yapacaÄŸÄ± ÅŸey ÅŸudur; **belirlenen adresin tÃ¼m linklerini taramak ve listelemektir.** _Daha sonra da listelediÄŸi bu linklere sÄ±rasÄ±yla gider.  
_Bu iÅŸlemi otomatize etmek de `Web Crawler` kavramÄ±nÄ± doÄŸurur.

### Web Scraping
[Neydi bu olay](https://kekikakademi.site/Python-ile-Veri-Kazima?cda=); _Web crawler bir linkâ€™e uÄŸradÄ±ÄŸÄ± zaman_ **devreye Web Scraping kavramÄ± girer.  
Web Scraping**, **linkâ€™teki belirtilen alanlarÄ±n toplanmasÄ± iÅŸlemidir.** Yani bir nevi; veri toplama veya yÄ±ÄŸÄ±ndan veri Ã§Ä±karma olayÄ±dÄ±r.
 `Web Crawler` ve `Web Scraping`_birbirleriyle partner olan kavramlar._

### Kod ZamanÄ±
Ã–ncelikle biz bir robot yazÄ±yoruz deÄŸil mi?  
BakalÄ±m ilgili site robotlara ne tavsiye etmiÅŸ?

![dizibox.pw/robots.txt](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/3_dizibox_robots_txt.png)

â™¦ Sitemap'e bakÄ±p kendimize uygun haritayÄ± bulalÄ±m ve oraya istek yollayalÄ±m.

â™¦ ArdÄ±ndan bir betik oluÅŸturup kÃ¼tÃ¼phaneleri ekleyerek baÅŸlayalÄ±m;

    import requests                 # Websitelerine istek atmamÄ±zÄ± saÄŸlayacak arkadaÅŸ
    from bs4 import BeautifulSoup   # HTML veya XML dosyalarÄ±nÄ± okuyan arkadaÅŸ

â™¦ ArdÄ±ndan isteÄŸimizi gÃ¶nderip cevabÄ±mÄ±za bakalÄ±m;

    link = "https://www.dizibox.pw/sitemap-tax-diziler.xml"
    
    istek = requests.get(link)   # link'e istek gÃ¶nderiyoruz
    
    print(istek)                 # <Response [?]>

![Response](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/1_Response.png)

**Ne oldu?** _403 verdi.._
**Yani?**

![HTTP Status Codes](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/2_HTTP_Status_Codes.png)

**NeymiÅŸ _403_ ?**
`Forbidden`  **EriÅŸim Engellendi**

**Neden Peki ?**
Ä°stek yolladÄ±ÄŸÄ±mÄ±z site bizi istemiyor olabilir.  
`robots.txt` ne diyordu?

Her tÃ¼rlÃ¼ `User-Agent` yani **kimlik** kabulÃ¼m diyordu.  
_User-Agent tanÄ±mlamamÄ±z gerekiyor.._

**Deneyelim;**

![User-Agent : @KekikAkademi](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/4_User-Agent_KekikAkademi.png)

**NeymiÅŸ?** _Yalan SÃ¶ylemiÅŸ :)_

Åimdi **gerÃ§ek** bir kimlik sunalÄ±m:  
_iyi hoÅŸ da_; **GerÃ§ek KimliÄŸi nasÄ±l bulacaÄŸÄ±z?**

![User-Agent Bulmak](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/5_User-Agent-Bulmak.png)

1.  TarayÄ±cÄ±mÄ±zla gerÃ§ek bir kullanÄ±cÄ± olarak websitesine gireceÄŸiz.
2.  SaÄŸ tÄ±klayÄ±p "SayfayÄ± Ä°ncele" veya "Ã–ÄŸeyi Denetle" olan bÃ¶lÃ¼mÃ¼ aÃ§acaÄŸÄ±z.
3.  "Network" sekmesi altÄ±ndaki "Headers" a geleceÄŸiz.
4.  Kendimiz, ÅŸuan hangi kimlik ile istek attÄ±ÄŸÄ±mÄ±za bakacaÄŸÄ±z.
5.  Bu kimliÄŸi kullanarak istek atmayÄ± deneyeceÄŸiz.
######
    #!/usr/bin/env python
    #! -*- coding: utf-8 -*-
    # Bu araÃ§ @keyiflerolsun tarafÄ±ndan | @KekikAkademi iÃ§in yazÄ±lmÄ±ÅŸtÄ±r.
    
    #---------------------------------------------------------------------------------#
    import requests                 # Websitelerine istek atmamÄ±zÄ± saÄŸlayacak arkadaÅŸ
    from bs4 import BeautifulSoup   # HTML veya XML dosyalarÄ±nÄ± okuyan arkadaÅŸ
    #---------------------------------------------------------------------------------#
    
    link = "https://www.dizibox.pw/sitemap-tax-diziler.xml"
    # GerÃ§ek Bir TarayÄ±cÄ± OlmamÄ±z LazÄ±m!
    kimlik = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'}
    istek = requests.get(link, headers=kimlik)       # link'e kimlik bilgimizle istek gÃ¶nderiyoruz
    
    print(istek)                    # <Response [?]>

![Response 200](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/6_Response_200.png)

**Haarika !**

â™¦ ArtÄ±k dÃ¶nen bir verimiz var ve bunu BeautifulSoup ile iÅŸleyeceÄŸiz..

    soup = BeautifulSoup(istek.text, "html5lib")        # Gelen veriyi html5lib ile ayrÄ±ÅŸtÄ±rmaya baÅŸlÄ±yoruz
    
    print(soup)

![Gelen Veri (soup)](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/7_Gelen_Veri.png)

**Evveeet!** 
Sonunda tarayÄ±cÄ± Ã¼zerinden eriÅŸebildiÄŸimiz yere python ile ulaÅŸmayÄ± baÅŸardÄ±k!  
SayfanÄ±n tamamÄ± elimizde. Åimdi ayÄ±klama zamanÄ±!

**EkranÄ±mÄ±zda ne var bize lazÄ±m olan?** _Dizi BaÄŸlantÄ±larÄ±(Linkleri).._

â™¦ **Nerede bu linkler?** `<loc>`  _diye biÅŸeyin iÃ§inde.._ **AyÄ±klayalÄ±m!**

    print(soup.find('loc'))         # Kaynak Kodundaki <loc>

![<loc>](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/8_loc.png)

**Tuttuk Mu? :)**

`soup.find` diye ayÄ±kladÄ±k ya hani; birde bunun `findAll` versiyonu var ;)

    print(soup.findAll('loc'))      # Kaynak Kodundaki <loc>'lar

![findAll('loc)](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/9_findAll_loc.png)

**Ne Oldu?** _Hepsini tablo iÃ§inde verdi.._

bu `findAll` olan arkadaÅŸÄ± `for` dÃ¶ngÃ¼sÃ¼ iÃ§erisinde kullanÄ±rsak; _yinelenebilir bir nesne dÃ¶ndÃ¼rÃ¼yor..._

    for gelenlink in soup.findAll('loc'):
        print(gelenlink)

![for gelenlink in soup.findAll('loc'):](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/10_for_findAll_loc.png)

**Hoppalaaa?** Tamam dÃ¼zgÃ¼n verdi ama!!!

KardeÅŸim dur iki dakika sana aÅŸama aÅŸama Ã¶ÄŸretiyoruz .  
Geldi mi babacÄ±m satÄ±r satÄ±r dÃ¼zgÃ¼nce? Geldi.  
Åimdi kod bloÄŸundan sÄ±yÄ±rmak iÃ§in sadece ÅŸunu yapÄ±caz;

    for gelenlink in soup.findAll('loc'):
        print(gelenlink.text)

![gelenlink.text](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/11_for_findAll_loc_gelenveri_text.png)

**ulan sadece .text ekledin :)** _Atla deve deÄŸil, sen asÄ±l olayÄ± seyret ÅŸimdi :)_

### KodlarÄ± ToparlayalÄ±m

    #!/usr/bin/env python
    #! -*- coding: utf-8 -*-
    # Bu araÃ§ @keyiflerolsun tarafÄ±ndan | @KekikAkademi iÃ§in yazÄ±lmÄ±ÅŸtÄ±r.
    
    #---------------------------------------------------------------------------------#
    import requests                 # Websitelerine istek atmamÄ±zÄ± saÄŸlayacak arkadaÅŸ
    from bs4 import BeautifulSoup   # HTML veya XML dosyalarÄ±nÄ± okuyan arkadaÅŸ
    #---------------------------------------------------------------------------------#
    
    #----------------------------------------------------------------------------------------------------------------------#
    link = "https://www.dizibox.pw/sitemap-tax-diziler.xml"
    # GerÃ§ek Bir TarayÄ±cÄ± OlmamÄ±z LazÄ±m!
    kimlik = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36'}
    istek = requests.get(link, headers=kimlik)          # link'e kimlik bilgimizle istek gÃ¶nderiyoruz
    soup = BeautifulSoup(istek.text, "html5lib")        # Gelen veriyi html5lib ile ayrÄ±ÅŸtÄ±rmaya baÅŸlÄ±yoruz
    #----------------------------------------------------------------------------------------------------------------------#
    
    #-------------------------------------------------------------#
    #print(istek)                    # <Response [200]>
    #print(soup)                     # Kaynak Kodlar
    #print(soup.find('loc'))         # Kaynak Kodundaki <loc>
    #print(soup.findAll('loc'))      # Kaynak Kodundaki <loc>'lar
    #-------------------------------------------------------------#
    
    for gelenlink in soup.findAll('loc'):
        print(gelenlink.text)

**Senaryomuzun yarÄ±sÄ±nÄ± tamamladÄ±k.**

**Neydi?** _Siteden dÃ¼zgÃ¼n yanÄ±t al ve bÃ¼tÃ¼n dizi linklerini toparla._

Åimdi bu gelen linklere tek tek girme vakti.

    for dizi_adresleri in soup.findAll('loc'):                              # Ã–rÃ¼mceÄŸimizi BaÅŸlattÄ±k!
        diziLink = dizi_adresleri.text                                      # Crawl ettiÄŸimiz linkler = Dizi Linkleri
                                                                            # Bu linklerin iÃ§ine girelim
        dizi_istek = requests.get(dizi_adresleri.text, headers=kimlik)      # Her gelen link'e istek atÄ±yorz
        dizi_icerik = BeautifulSoup(dizi_istek.text, "html5lib")            # html5lib ile parse ediyoruz
        
        print(f"Nerdeyim? : {dizi_adresleri.text}")                         # istek attÄ±ÄŸÄ±mÄ±z yeri ekrana yazdÄ±r
        print(dizi_icerik)                                                  # Kaynak Kodlar ekrana yazdÄ±r
        break                                                               # DÃ¶ngÃ¼yÃ¼ KÄ±r > Linklerin Hepsini Tarama!

![Scraping BaÅŸlangÄ±cÄ±](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/12_scraping_baslangici.png)

**NaptÄ±k?**

1.  Ã–rÃ¼mceÄŸi baÅŸlat
2.  dizi linklerini toplamÄ±ÅŸtÄ±k zaten
3.  bu linklerin iÃ§ine gir(istek at)
4.  kaynak kodlarÄ±na ulaÅŸ
5.  ekrana nerede olduÄŸumuzu yazdÄ±r
6.  kaynak kodlarÄ±nÄ± yazdÄ±r
7.  dÃ¶ngÃ¼yÃ¼ kÄ±r

1.  dÃ¶ngÃ¼ iÃ§erisinde olduÄŸumuz iÃ§in
2.  bÃ¼tÃ¼n linkleri gezmeden bitmez!

_Geldi Mi?_ **Geldi!**

**Devaaaam!**

Hadi dizi adÄ±nÄ± alalÄ±m, Ã§ok basit!

    print(dizi_icerik.title.text)   # BulunduÄŸumuz Sayfa BaÅŸlÄ±ÄŸÄ±nÄ± yazdÄ±r

![Dizi BaÅŸlÄ±ÄŸÄ±](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/13_dizi_basligi.png)

istediÄŸimiz gibi geldi mi? HayÄ±r.

`.replace("falan","filan")` Ã–zelliÄŸini KullanalÄ±m..

    print(dizi_icerik.title.text.replace(" izle | DiziBOX", ""))

![Dizi BaÅŸlÄ±ÄŸÄ± .replace("","")](https://teletype.in/files/62/51/6251fcdb-da22-47b3-a06b-35d63c5b8e43.png)

**NaptÄ±k?** _"izle | DiziBOX"_, olan yeri _""_ hiÃ§bir ÅŸey ile deÄŸiÅŸtirdik ve istediÄŸimiz sonucu elde ettik!

Devam etmeden Ã¶nce kodlarÄ±mÄ±zÄ±n son haline gÃ¶z atalÄ±m;

![KodlarÄ±n Son Hali](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/14_kodlarin_son_hali.png)

> YazÄ± sonunda bu kodlarÄ±n hepsi [github](https://github.com/KekikAkademi) Ã¼zerinden paylaÅŸÄ±lacak.

Dizi Ã¼lkesi ve tÃ¼rÃ¼nÃ¼ de Ã§ektik mi tamamdÄ±r bu senaryo.

**ÅŸimdiiiii.....**

Gelen dizi baÅŸlÄ±ÄŸÄ± hangi adresten geliyordu?  
`https://www.dizibox.pw/diziler/100-days-to-victory/`

Bu adrese gidip ayÄ±klamak istediÄŸimiz alanÄ±n kaynaÄŸÄ±na bakalÄ±m;

![Dizi Ãœlkesi](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/15_diziUlkesi.png)

**NerdeymiÅŸ dizi Ã¼lkesi bilgimiz?**

`<a` 'nÄ±n `rel="tag"` etiketi iÃ§erisinde yazÄ± olarak geÃ§iyormuÅŸ. Deneyelim bakalÄ±m kazÄ±mayÄ±..

    diziUlke = dizi_icerik.find("a", attrs={"rel": "tag"}).text
    
    print(diziUlke)

![Dizi Ãœlkesi Ã‡Ä±ktÄ±](https://github.com/KekikAkademi/KekikDiziBotu/raw/master/img/16_diziUlkesi_cikti.png)

`break` ile dÃ¶ngÃ¼yÃ¼ kÄ±rdÄ±ÄŸÄ±mÄ±z zaman **Ä°ngiltere** Ã§Ä±ktÄ±sÄ±nÄ± aldÄ±k.  
dÃ¶ngÃ¼yÃ¼ kÄ±rmayÄ±p devam ettirirsek sÄ±rayla diÄŸer sayfalarÄ± taramaya devam edip Ã§Ä±ktÄ±larÄ± verdi.

Ancak ÅŸÃ¶yle bir sÄ±kÄ±ntÄ±mÄ±z var;

`[https://www.dizibox.pw/diziler/100-days-to-victory/]` adresinde Ãœlke bilgisinde **Ä°ngiltere, Kanada** yazÄ±yor..

Demek ki doÄŸru kazÄ±ma yapamamÄ±ÅŸÄ±z. Kodumuzla oynayarak doÄŸru Ã§Ä±ktÄ±yÄ± yakalamaya Ã§alÄ±ÅŸÄ±yoruz..

    diziBilgi = []
    
    for diziData in dizi_icerik.findAll("a", attrs={"rel": "tag"}):     # BulunduÄŸumuz sayfa iÃ§erisinde Dizi Bilgisi
    	diziBilgi.append(diziData.text)
    
    a = ''.join(map(str, diziBilgi[1]))[0]
    
    if a != '2':
    	diziUlkesi = ', '.join(map(str, diziBilgi[:2]))
    	print(diziUlkesi)
    elif a == '1':
    	diziUlkesi = ', '.join(map(str, diziBilgi[:1]))
    	print(diziUlkesi)
    else:
    	diziUlkesi = ', '.join(map(str, diziBilgi[:1]))
    	print(diziUlkesi)

[gibi gibi fantezilere girilebilir](https://github.com/KekikAkademi/KekikDiziBotu/blob/master/KekikDiziBotu.py#L51) tabiki ama konumuzdan Ã§ok uzakta :) biz tek Ã¼lke ile devam edelim aÃ§Ä±kÃ§asÄ± bitsin istiyorum artÄ±k ÅŸu yazÄ± :D

velhasÄ±l bu matematikle beraber her dizinin iÃ§ine kadar gidebilirsiniz.

ve en son aÅŸamada, Ã¶rn' 1. sezon 1. bÃ¶lÃ¼m linkinin iÃ§erisinde video linki var ;

    https://www.dizibox.pw/freud-1-sezon-1-bolum-izle/5/
    > iÃ§erisinde
    
    https://odnoklassniki.ru/videoembed/1795922332305
    > linki var
    
    <a olanlarÄ± ve href="../odnoklassniki.ru/videoembed/"
    olan linkleri tut;
    
    .findAll('a', attrs={'href':
                  re.compile("^https://odnoklassniki.ru/videoembed/")})

gibi gibi ortalÄ±ÄŸÄ±n anasÄ±nÄ± bile aÄŸlatabilirsiniz.

KazÄ±ma iÅŸi Ã§ok sabÄ±r gerektiren bir iÅŸtir ve ben bu yazÄ± iÃ§in, aralÄ±klÄ± olarak, 13 saattir uÄŸraÅŸÄ±yorum artÄ±k sÄ±kÄ±ldÄ±m :)

Soru ve SorunlarÄ±nÄ±z iÃ§in [@KekikSiber](https://t.me/KekikSiber) 'den bizlere ulaÅŸabilirsiniz selam ve saygÄ± ile..

### Bu sayfada yazÄ±lan; [KodlarÄ±n TamamÄ± <<](https://github.com/KekikAkademi/KekikDiziBotu/blob/master/KekikDiziBotu.py)

_Ben bu betikte, dÃ¶nen veriyi print olarak aldÄ±m ama_  
**Siz nasÄ±l isterseniz Ã¶yle kullanabilirsiniz. Ã–rn.;**
-   database oluÅŸturun,
-   ister json oluÅŸturun,
-   ister telegram'dan mesaj olarak atÄ±n,

_gibi gibi,_ **dÃ¶nen veriyi nasÄ±l kullanacaÄŸÄ±nÄ±z size kalmÄ±ÅŸ.**

> GÃ¶rseller [carbon.now.sh](https://carbon.now.sh/?bg=rgba(31%252C129%252C109%252C1)&t=night-owl&wt=none&l=auto&ds=false&dsyoff=20px&dsblur=68px&wc=false&wa=true&pv=56px&ph=56px&ln=false&fl=1&fm=Hack&fs=14px&lh=143%2525&si=false&es=2x&wm=false) SayfasÄ± ile OluÅŸturulmuÅŸtur..  

________________________________________________
ğŸ“ƒ **Yandex.Disk BÃ¼nyemizdeki veriler 1TB'a UlaÅŸmÄ±ÅŸtÄ±r.. ğŸŠ**

_PaylaÅŸÄ±lan KurslarÄ±n TÃ¼mÃ¼nÃ¼_ [**@KekikKahve**](https://t.me/KekikKahve) _Grubu notlarÄ±ndan Ã‡aÄŸÄ±rabilirsiniz.._

ğŸ•Šï¸ Bize **oy verip** _paylaÅŸarak_ destek olmaya ne dersin? âœŒğŸ¼
#
> Bu readme sayfasÄ± oluÅŸturulurken [prose.io](http://prose.io/ "prose.io") ve [stackedit.io](https://stackedit.io/app "stackedit.io") araÃ§larÄ±ndan yardÄ±m alÄ±nmÄ±ÅŸtÄ±r..
